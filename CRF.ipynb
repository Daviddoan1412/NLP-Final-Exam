{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CRF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Conditional Random Fields"
      ],
      "metadata": {
        "id": "0GKsn40IX9l5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5-YVU8k0V3f",
        "outputId": "ee95cc45-565d-4f89-ed0e-e85f26000725"
      },
      "source": [
        "!git clone https://github.com/VinAIResearch/PhoNER_COVID19.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PhoNER_COVID19'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 44 (delta 14), reused 30 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5VAEkH706e1"
      },
      "source": [
        "\n",
        "def load_data(directory):\n",
        "  sentence = []\n",
        "  res = []\n",
        "  with open(directory) as f:\n",
        "    for lines in f:\n",
        "      lines = lines.strip()\n",
        "      if(lines==\"\"):\n",
        "        res.append(sentence)\n",
        "        sentence = []\n",
        "      else:\n",
        "        word = lines.split(\" \")[0]\n",
        "        label = lines.split(\" \")[1]\n",
        "        sentence.append((word, label))\n",
        "  return res\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m7JnxGZ2i-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77001a7b-35c2-4209-f36c-828eb5f0c4a4"
      },
      "source": [
        "\n",
        "train_data = load_data(\"/content/PhoNER_COVID19/data/syllable/train_syllable.conll\")\n",
        "test_data = load_data(\"/content/PhoNER_COVID19/data/syllable/test_syllable.conll\")\n",
        "print(len(train_data))\n",
        "print(len(test_data))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5027\n",
            "3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1WMPK7K76QZ"
      },
      "source": [
        "def word2features(sentence, i):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "        sentence (list): list of words [w1, w2,...,w_n]\n",
        "        i (int): index of the word\n",
        "    Return:\n",
        "        features (dict): dictionary of features\n",
        "    \"\"\"\n",
        "    word = sentence[i]\n",
        "    features = {\n",
        "        'is_first': i == 0,\n",
        "        'is_last': i == len(sentence) - 1,\n",
        "        'is_first_capital': word[0].isupper(),\n",
        "        'is_all_caps': int(word.upper() == word),\n",
        "        'is_all_lower': word.lower() == word,\n",
        "        'word': word,\n",
        "        'word.lower()': word.lower(),\n",
        "        'prefix_1': word[0],\n",
        "        'prefix_2': word[:2],\n",
        "        'prefix_3': word[:3],\n",
        "        'prefix_4': word[:4],\n",
        "        'suffix_1': word[-1],\n",
        "        'suffix_2': word[-2:],\n",
        "        'suffix_3': word[-3:],\n",
        "        'suffix_4': word[-4:],\n",
        "        'prev_word': '' if i==0 else sentence[i-1].lower(),\n",
        "        'next_word': '' if i==len(sentence)-1 else sentence[i+1].lower(),\n",
        "        'has_hyphen': '-' in word,\n",
        "        'is_numeric': word.isdigit(),\n",
        "        'capitals_inside': word[1:].lower() != word[1:]\n",
        "    }\n",
        "    \n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sentence):\n",
        "    \"\"\"\n",
        "    sentence is a list of words [w1, w2,...,w_n]\n",
        "    \"\"\"\n",
        "    return [word2features(sentence, i) for i in range(len(sentence))]\n",
        "\n",
        "\n",
        "def sent2labels(sentence):\n",
        "    \"\"\"\n",
        "    sentence is a list of tuples (word, postag)\n",
        "    \"\"\"    \n",
        "    return [postag for token, postag in sentence]\n",
        "\n",
        "def untag(sentence):\n",
        "    \"\"\"\n",
        "    sentence is a list of tuples (word, postag)\n",
        "    \"\"\"\n",
        "    return [token for token, _ in sentence]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(untag(train_data[2]))\n",
        "print(train_data[2])\n",
        "print(sent2labels(train_data[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uaqg67Qpjuk6",
        "outputId": "82d7be31-2561-4a0a-e7f5-4870b6e44acf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ngoài', 'ra', ',', 'những', 'người', 'tiếp', 'xúc', 'gián', 'tiếp', '(', 'đã', 'gặp', 'những', 'người', 'tiếp', 'xúc', 'gần', 'với', 'bệnh', 'nhân', ')', 'được', 'lập', 'danh', 'sách', 'và', 'yêu', 'cầu', 'cách', 'ly', 'y', 'tế', 'tại', 'nơi', 'ở', '.']\n",
            "[('Ngoài', 'O'), ('ra', 'O'), (',', 'O'), ('những', 'O'), ('người', 'O'), ('tiếp', 'O'), ('xúc', 'O'), ('gián', 'O'), ('tiếp', 'O'), ('(', 'O'), ('đã', 'O'), ('gặp', 'O'), ('những', 'O'), ('người', 'O'), ('tiếp', 'O'), ('xúc', 'O'), ('gần', 'O'), ('với', 'O'), ('bệnh', 'O'), ('nhân', 'O'), (')', 'O'), ('được', 'O'), ('lập', 'O'), ('danh', 'O'), ('sách', 'O'), ('và', 'O'), ('yêu', 'O'), ('cầu', 'O'), ('cách', 'O'), ('ly', 'O'), ('y', 'O'), ('tế', 'O'), ('tại', 'O'), ('nơi', 'O'), ('ở', 'O'), ('.', 'O')]\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Sv1V9aN72WY",
        "outputId": "91879c57-663f-410e-e5c1-c9594b18fef7"
      },
      "source": [
        "sent2features(untag(train_data[2]))[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'capitals_inside': False,\n",
              " 'has_hyphen': False,\n",
              " 'is_all_caps': 0,\n",
              " 'is_all_lower': False,\n",
              " 'is_first': True,\n",
              " 'is_first_capital': True,\n",
              " 'is_last': False,\n",
              " 'is_numeric': False,\n",
              " 'next_word': 'ra',\n",
              " 'prefix_1': 'N',\n",
              " 'prefix_2': 'Ng',\n",
              " 'prefix_3': 'Ngo',\n",
              " 'prefix_4': 'Ngoà',\n",
              " 'prev_word': '',\n",
              " 'suffix_1': 'i',\n",
              " 'suffix_2': 'ài',\n",
              " 'suffix_3': 'oài',\n",
              " 'suffix_4': 'goài',\n",
              " 'word': 'Ngoài',\n",
              " 'word.lower()': 'ngoài'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XW5Im6Ll8OWR",
        "outputId": "39ee26bc-1743-4f59-cee3-0ccd8dbc30b5"
      },
      "source": [
        "X_train = [sent2features(untag(s)) for s in train_data]\n",
        "y_train = [sent2labels(s) for s in train_data]\n",
        "\n",
        "print(len(X_train))\n",
        "print(len(y_train))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5027\n",
            "5027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9U0NoF48Tdo",
        "outputId": "16dea2ca-0e50-442a-e25f-554a0f964949"
      },
      "source": [
        "\n",
        "!pip install -U 'scikit-learn<0.24'\n",
        "from itertools import chain\n",
        "\n",
        "import nltk\n",
        "import sklearn\n",
        "import scipy.stats\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "!pip install -U 'sklearn-crfsuite<0.24'\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn<0.24\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (3.0.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.23.2\n",
            "Collecting sklearn-crfsuite<0.24\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite<0.24) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite<0.24) (0.8.9)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "\u001b[K     |████████████████████████████████| 743 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite<0.24) (4.62.3)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6b3vLGz8WLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad8043c-812c-4808-edf5-8d891ad1d6a4"
      },
      "source": [
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='l2sgd',\n",
        "    c2=3.2,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True,\n",
        "    all_possible_states=True,\n",
        ")\n",
        "crf.fit(X_train, y_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='l2sgd', all_possible_states=True, all_possible_transitions=True,\n",
              "    c2=3.2, keep_tempfiles=None, max_iterations=100)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV_nxZZN8r-J"
      },
      "source": [
        "with open('output.txt', 'w') as f:\n",
        "    for i in range(len(test_data)):\n",
        "        for j in range(len(test_data[i])):\n",
        "          f.write(test_data[i][j][0]+' '+test_data[i][j][1]+'\\n')\n",
        "        f.write('\\n')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UleBNOhIBhXx"
      },
      "source": [
        "with open('answer.txt', 'w') as f:\n",
        "    for i in range(len(test_data)):\n",
        "      X_test = [sent2features(untag(test_data[i]))]\n",
        "      y_pred = crf.predict(X_test)\n",
        "      for j in range(len(test_data[i])):\n",
        "           f.write(test_data[i][j][0]+' '+y_pred[0][j]+'\\n')\n",
        "      f.write('\\n')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74J_uvfyBkIQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e51ec88-2b07-4a75-ef77-834ee4f7611b"
      },
      "source": [
        "!pip install seqeval[cpu]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval[cpu]\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▌                        | 10 kB 40.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval[cpu]) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval[cpu]) (0.23.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval[cpu]) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval[cpu]) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval[cpu]) (3.0.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=23d80a1d214d7981bd60671af9ae50e8fd073a87eba618f7a40f08b8d46b2f4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovr-qnoPBmGJ"
      },
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def get_tags(filepath):\n",
        "    res = []\n",
        "    with open(filepath, 'r') as f:\n",
        "        cur_sen = []\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line == '':\n",
        "                if len(cur_sen) != 0:\n",
        "                    res.append(cur_sen)\n",
        "                    cur_sen = []\n",
        "            else:\n",
        "                word, tag = line.split()\n",
        "                cur_sen.append(tag)\n",
        "    if len(cur_sen) != 0:\n",
        "        res.append(cur_sen)\n",
        "    return res\n",
        "\n",
        "def evaluate(test_file, output_file):\n",
        "    y_true = get_tags(test_file)\n",
        "    y_pred = get_tags(output_file)\n",
        "\n",
        "    p = precision_score(y_true, y_pred)\n",
        "    r = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    return p, r, f1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpCVUr7TBz9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "124505da-6ca3-4906-8c60-8694e6456cce"
      },
      "source": [
        "evaluate('./answer.txt', './output.txt')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8788240306774606, 0.9158969804618117, 0.896977603826919)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo"
      ],
      "metadata": {
        "id": "h8gHgK-DCTAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Xin mơi nghe hướng dẫn của Bộ Y tế. Vào ngày 23 tháng 4 , Bệnh nhân số 234 hiện đã mắc Covid được phát hiện tại nhà riêng ở số 64 đường Đông Tác, Đông thọ. Bệnh nhân đang được chuyển tới bệnh viện nhiệt đới trung ương để được chăm sóc\"\n",
        "\n",
        "res = sentence.split()\n",
        "print(res)\n",
        "\n",
        "X = [sent2features(res)]\n",
        "y = crf.predict(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k043I0IDCZVu",
        "outputId": "c43ba317-4dd7-4328-d316-9c810dccf8cc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Xin', 'mơi', 'nghe', 'hướng', 'dẫn', 'của', 'Bộ', 'Y', 'tế.', 'Vào', 'ngày', '23', 'tháng', '4', ',', 'Bệnh', 'nhân', 'số', '234', 'hiện', 'đã', 'mắc', 'Covid', 'được', 'phát', 'hiện', 'tại', 'nhà', 'riêng', 'ở', 'số', '64', 'đường', 'Đông', 'Tác,', 'Đông', 'thọ.', 'Bệnh', 'nhân', 'đang', 'được', 'chuyển', 'tới', 'bệnh', 'viện', 'nhiệt', 'đới', 'trung', 'ương', 'để', 'được', 'chăm', 'sóc']\n",
            "[['O', 'O', 'O', 'O', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'O', 'B-DATE', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'B-PATIENT_ID', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PATIENT_ID', 'B-LOCATION', 'I-LOCATION', 'I-LOCATION', 'I-LOCATION', 'I-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n"
          ]
        }
      ]
    }
  ]
}